# Flask/llama_client.py
"""
Client Python pour communiquer avec le serveur Llama.cpp
G√®re la g√©n√©ration de rapports d'analyse g√©opolitique
Version optimis√©e avec gestion d'erreurs robuste
"""

import logging
import requests
from typing import Dict, List, Optional
from datetime import datetime

logger = logging.getLogger(__name__)


class LlamaClient:
    """Client pour interagir avec llama.cpp server"""
    
    def __init__(self, endpoint: str = "http://localhost:8080"):
        self.endpoint = endpoint
        self.timeout = 180  # 3 minutes pour analyses longues
        
        # Templates de prompts par type de rapport
        self.prompt_templates = {
            'geopolitique': self._build_geopolitique_prompt,
            'economique': self._build_economique_prompt,
            'securite': self._build_securite_prompt,
            'synthese': self._build_synthese_prompt
        }
    
    def test_connection(self) -> bool:
        """Teste la connexion au serveur Llama"""
        try:
            response = requests.get(
                f"{self.endpoint}/health",
                timeout=5
            )
            return response.status_code == 200
        except Exception as e:
            logger.error(f"Connexion Llama √©chou√©e: {e}")
            return False
    
    def _build_geopolitique_prompt(self, articles: List[Dict], 
                                   context: Dict) -> str:
        """Construit le prompt pour analyse g√©opolitique"""
        
        # R√©sum√© des sentiments
        sentiment_summary = f"""
Positifs: {context.get('sentiment_positive', 0)} articles
N√©gatifs: {context.get('sentiment_negative', 0)} articles
Neutres: {context.get('sentiment_neutral', 0)} articles
"""
        
        # Top articles
        top_articles = "\n".join([
            f"- {art['title']} ({art.get('source', 'source inconnue')})"
            for art in articles[:10]
        ])
        
        themes_text = ", ".join(context.get('themes', [])) or "Tous th√®mes"
        
        prompt = f"""Tu es GEOPOL, expert en analyse g√©opolitique. Produis un rapport structur√© et factuel.

CONTEXTE
========
P√©riode: {context.get('period', 'Non sp√©cifi√©e')}
Articles: {len(articles)}
Th√®mes: {themes_text}

SENTIMENTS
==========
{sentiment_summary}

ARTICLES CL√âS
=============
{top_articles}

RAPPORT DEMAND√â
===============

## 1. SYNTH√àSE EX√âCUTIVE
R√©sum√© en 2-3 phrases des tendances majeures

## 2. ANALYSE DES TENDANCES
- 3-4 tendances g√©opolitiques principales
- Contexte, acteurs, implications pour chacune

## 3. POINTS DE TENSION
- Zones de conflit ou tensions croissantes
- Causes sous-jacentes
- Niveau de risque (faible/moyen/√©lev√©)

## 4. PERSPECTIVES
- Sc√©narios probables (1-3 mois)
- Actions de veille recommand√©es
- Indicateurs √† surveiller

CONSIGNES:
- Factuel et nuanc√©
- Bas√© UNIQUEMENT sur les articles fournis
- Ton professionnel
- 800-1200 mots

Commence par "## 1. SYNTH√àSE EX√âCUTIVE".
"""
        return prompt
    
    def _build_economique_prompt(self, articles: List[Dict], 
                                 context: Dict) -> str:
        """Construit le prompt pour analyse √©conomique"""
        
        top_articles = "\n".join([
            f"- {art['title']}"
            for art in articles[:10]
        ])
        
        prompt = f"""Tu es un analyste √©conomique senior. Produis une analyse structur√©e.

DONN√âES
=======
P√©riode: {context.get('period', 'Non sp√©cifi√©e')}
Articles: {len(articles)}

TITRES CL√âS
===========
{top_articles}

RAPPORT √âCONOMIQUE
==================

## 1. INDICATEURS MACRO√âCONOMIQUES
- Tendances √©conomiques (croissance, inflation, march√©s)
- Secteurs en mouvement

## 2. POLITIQUES √âCONOMIQUES
- D√©cisions politiques majeures
- Impact sur les march√©s
- R√©ponses des acteurs

## 3. RISQUES ET OPPORTUNIT√âS
- Risques syst√©miques
- Opportunit√©s d'investissement
- Recommandations

## 4. PR√âVISIONS
- Sc√©narios 3-6 mois
- Facteurs de volatilit√©

600-900 mots. Commence par "## 1. INDICATEURS MACRO√âCONOMIQUES".
"""
        return prompt
    
    def _build_securite_prompt(self, articles: List[Dict], 
                               context: Dict) -> str:
        """Construit le prompt pour analyse s√©curit√©"""
        
        top_articles = "\n".join([
            f"- {art['title']}"
            for art in articles[:8]
        ])
        
        prompt = f"""Tu es un expert en s√©curit√© internationale. Produis un briefing s√©curitaire.

CONTEXTE
========
P√©riode: {context.get('period', 'Non sp√©cifi√©e')}
Articles: {len(articles)}

√âV√âNEMENTS
==========
{top_articles}

BRIEFING S√âCURITAIRE
====================

## 1. MENACES √âMERGENTES
- Nouvelles menaces ou escalades
- Niveau de risque

## 2. ACTEURS ET DYNAMIQUES
- Acteurs impliqu√©s
- Rapports de force

## 3. IMPLICATIONS R√âGIONALES
- Impact sur la stabilit√©
- Risques de contagion

## 4. RECOMMANDATIONS
- Mesures de vigilance
- Zones prioritaires

500-800 mots. Commence par "## 1. MENACES √âMERGENTES".
"""
        return prompt
    
    def _build_synthese_prompt(self, articles: List[Dict], 
                               context: Dict) -> str:
        """Construit le prompt pour synth√®se hebdomadaire"""
        
        top_articles = "\n".join([
            f"- {art['title']}"
            for art in articles[:15]
        ])
        
        prompt = f"""Tu es GEOPOL, sp√©cialiste en synth√®se d'actualit√©. Produis une synth√®se hebdomadaire.

P√âRIODE
=======
{context.get('period', 'Derni√®re semaine')}
{len(articles)} articles

ARTICLES MAJEURS
================
{top_articles}

SYNTH√àSE HEBDOMADAIRE
=====================

## 1. FAITS MARQUANTS
- 5 √©v√©nements majeurs (une phrase chacun)

## 2. TENDANCES
- 3 tendances significatives
- Importance strat√©gique

## 3. √âVOLUTIONS G√âOPOLITIQUES
- Changements dans les √©quilibres
- Nouvelles alliances ou tensions

## 4. AGENDA √Ä VENIR
- √âv√©nements √† surveiller
- √âch√©ances importantes

600-900 mots. Commence par "## 1. FAITS MARQUANTS".
"""
        return prompt
    
    def generate_analysis(self, report_type: str, articles: List[Dict],
                         context: Dict) -> Dict:
        """
        G√©n√®re une analyse avec Llama
        
        Args:
            report_type: Type (geopolitique, economique, securite, synthese)
            articles: Liste d'articles √† analyser
            context: Contexte (p√©riode, th√®mes, sentiments)
            
        Returns:
            Dict avec 'success', 'analysis', et √©ventuellement 'error'
        """
        
        # Test connexion
        if not self.test_connection():
            logger.warning("‚ö†Ô∏è Serveur Llama inaccessible - mode d√©grad√©")
            return {
                'success': False,
                'error': 'Serveur Llama inaccessible',
                'analysis': self._generate_fallback_analysis(
                    report_type, articles, context
                )
            }
        
        try:
            # Construire le prompt
            prompt_builder = self.prompt_templates.get(
                report_type, 
                self._build_geopolitique_prompt
            )
            prompt = prompt_builder(articles, context)
            
            logger.info(f"ü¶ô Envoi prompt √† Llama ({len(prompt)} caract√®res)")
            
            # Format instruction (optimal pour Llama 3)
            instruction_prompt = f"""### Instruction:
Tu es un analyste g√©opolitique professionnel. Analyse les articles ci-dessous et produis un rapport structur√©.

### Articles √† analyser:
{prompt}

### Rapport d'analyse:
"""
            
            # Appel API
            response = requests.post(
                f"{self.endpoint}/completion",
                json={
                    "prompt": instruction_prompt,
                    "temperature": 0.7,
                    "max_tokens": 2500,
                    "stop": ["###", "\n\n\n\n"],
                    "stream": False
                },
                headers={"Content-Type": "application/json"},
                timeout=self.timeout
            )
            
            logger.info(f"üì• R√©ponse HTTP: {response.status_code}")
            
            if response.status_code != 200:
                raise Exception(f"Erreur serveur: {response.status_code}")
            
            data = response.json()
            analysis_text = data.get('content', '').strip()
            
            if not analysis_text or len(analysis_text) < 200:
                raise Exception(f"R√©ponse invalide ({len(analysis_text)} chars)")
            
            logger.info(f"‚úÖ Analyse g√©n√©r√©e ({len(analysis_text)} caract√®res)")
            
            return {
                'success': True,
                'analysis': analysis_text,
                'model_used': 'llama3.2-3b-Q4_K_M',
                'prompt_tokens': len(prompt.split()),
                'completion_tokens': len(analysis_text.split())
            }
            
        except requests.Timeout:
            logger.error("‚è±Ô∏è Timeout Llama")
            return {
                'success': False,
                'error': 'Timeout - analyse trop longue',
                'analysis': self._generate_fallback_analysis(
                    report_type, articles, context
                )
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur Llama: {e}")
            return {
                'success': False,
                'error': str(e),
                'analysis': self._generate_fallback_analysis(
                    report_type, articles, context
                )
            }
    
    def _generate_fallback_analysis(self, report_type: str, 
                                    articles: List[Dict],
                                    context: Dict) -> str:
        """G√©n√®re une analyse de secours (mode d√©grad√©)"""
        
        # Gestion du cas o√π articles est vide
        if not articles:
            return f"""
## RAPPORT {report_type.upper()} - MODE D√âGRAD√â

**‚ö†Ô∏è Aucun article disponible pour l'analyse**

P√©riode: {context.get('period', 'Non sp√©cifi√©e')}
Th√®mes: {', '.join(context.get('themes', ['Tous th√®mes']))}

Aucun article n'a √©t√© trouv√© pour g√©n√©rer cette analyse.

---
*G√©n√©r√© par GEOPOL Analytics - {datetime.now().strftime('%d/%m/%Y √† %H:%M')}*
"""
        
        # Compter les sentiments
        sentiment_counts = {'positive': 0, 'negative': 0, 'neutral': 0}
        for article in articles:
            sentiment = article.get('sentiment', 'neutral')
            sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1
        
        # Calcul des pourcentages avec s√©curit√©
        total_articles = len(articles)
        positive_pct = (sentiment_counts['positive'] / total_articles * 100) if total_articles > 0 else 0
        negative_pct = (sentiment_counts['negative'] / total_articles * 100) if total_articles > 0 else 0
        neutral_pct = (sentiment_counts['neutral'] / total_articles * 100) if total_articles > 0 else 0
        
        # Sources principales
        sources = {}
        for article in articles:
            source = article.get('source', 'Source inconnue')
            sources[source] = sources.get(source, 0) + 1
        
        top_sources = sorted(sources.items(), key=lambda x: x[1], reverse=True)[:3]
        
        # G√©n√©rer le rapport de secours
        analysis = f"""
## RAPPORT {report_type.upper()} - MODE D√âGRAD√â

**‚ö†Ô∏è Note:** Ce rapport a √©t√© g√©n√©r√© en mode d√©grad√© (serveur IA indisponible). L'analyse est limit√©e aux statistiques descriptives.

### üìä Vue d'ensemble

**P√©riode:** {context.get('period', 'Non sp√©cifi√©e')}  
**Articles:** {total_articles}  
**Th√®mes:** {', '.join(context.get('themes', ['Tous th√®mes']))}

### üìà Distribution des sentiments

- **Positifs:** {sentiment_counts['positive']} articles ({positive_pct:.1f}%)
- **N√©gatifs:** {sentiment_counts['negative']} articles ({negative_pct:.1f}%)
- **Neutres:** {sentiment_counts['neutral']} articles ({neutral_pct:.1f}%)

### üì∞ Sources principales

{chr(10).join([f'{i+1}. {source} ({count} articles)' for i, (source, count) in enumerate(top_sources)])}

### üìã Articles significatifs

{chr(10).join([f'**{i+1}.** {article["title"]}' for i, article in enumerate(articles[:5])])}

### ‚ö†Ô∏è Limitations

Cette analyse automatique ne remplace pas l'expertise humaine. 

**Pour une analyse approfondie avec IA :**
1. V√©rifiez que le serveur Llama est d√©marr√© : `http://localhost:8080/health`
2. Relancez la g√©n√©ration du rapport
3. Ou consultez les articles individuellement

---
*G√©n√©r√© par GEOPOL Analytics - {datetime.now().strftime('%d/%m/%Y √† %H:%M')}*
"""
        
        return analysis


# Instance globale (singleton)
_llama_client = None

def get_llama_client() -> LlamaClient:
    """Retourne l'instance singleton du client Llama"""
    global _llama_client
    if _llama_client is None:
        _llama_client = LlamaClient()
        logger.info("‚úÖ LlamaClient initialis√©")
    return _llama_client