import logging
import threading
from typing import Dict, Any, List, Tuple
import numpy as np

# Importations conditionnelles
try:
    from textblob import TextBlob
    TEXTBLOB_AVAILABLE = True
except ImportError:
    TEXTBLOB_AVAILABLE = False
    print("‚ö†Ô∏è TextBlob non disponible")

try:
    import nltk
    from nltk.sentiment import SentimentIntensityAnalyzer
    NLTK_AVAILABLE = True
except ImportError:
    NLTK_AVAILABLE = False
    print("‚ö†Ô∏è NLTK non disponible")

try:
    from transformers import pipeline
    ROBERTA_AVAILABLE = True
    print("‚úÖ Transformers disponible - RoBERTa activable")
except ImportError:
    ROBERTA_AVAILABLE = False
    print("‚ö†Ô∏è Transformers non disponible")

logger = logging.getLogger(__name__)

class SentimentAnalyzer:
    def __init__(self):
        self.sia = None
        self.roberta_pipeline = None
        
        # üéØ LEXIQUE G√âOPOLITIQUE
        self.geopolitical_modifiers = {
            # Termes n√©gatifs sp√©cifiques
            'conflit': -0.4, 'guerre': -0.6, 'invasion': -0.7,
            'sanction': -0.5, 'embargo': -0.5, 'crise': -0.4,
            'tension': -0.3, 'menace': -0.4, 'attaque': -0.6,
            'bombardement': -0.7, 'victime': -0.5, 'destruction': -0.6,
            'r√©fugi√©': -0.4, 'famine': -0.6, 'r√©pression': -0.5,
            
            # Termes positifs sp√©cifiques
            'accord': 0.4, 'paix': 0.5, 'coop√©ration': 0.4,
            'diplomatie': 0.3, 'n√©gociation': 0.3, 'trait√©': 0.4,
            'alliance': 0.4, 'stabilit√©': 0.3, 'd√©veloppement': 0.3,
            'croissance': 0.3, 'investissement': 0.3, 'partenariat': 0.4,
            
            # Termes neutres contextuels
            '√©lection': 0.0, 'sommet': 0.0, 'r√©union': 0.0,
            'd√©claration': 0.0, 'annonce': 0.0, 'visite': 0.0
        }
        
        # üìä SEUILS CALIBR√âS (bas√©s sur analyse de corpus g√©opolitique)
        self.thresholds = {
            'positive': 0.25,           # Plus bas qu'avant
            'neutral_positive': 0.08,   # Zone tampon plus large
            'neutral_negative': -0.08,  # Sym√©trique
            'negative': -0.25           # Plus bas qu'avant
        }
        
        self._initialize_nltk()
        self._initialize_roberta()
    
    def _initialize_nltk(self):
        """Initialise NLTK en arri√®re-plan"""
        if not NLTK_AVAILABLE:
            return
            
        def download_nltk_data():
            try:
                nltk.data.find('vader_lexicon')
                logger.info("‚úÖ VADER lexicon d√©j√† disponible")
            except LookupError:
                logger.info("üì• T√©l√©chargement de VADER lexicon...")
                nltk.download('vader_lexicon', quiet=True)
                logger.info("‚úÖ VADER lexicon t√©l√©charg√©")
            
            self.sia = SentimentIntensityAnalyzer()
        
        thread = threading.Thread(target=download_nltk_data)
        thread.daemon = True
        thread.start()
    
    def _initialize_roberta(self):
        """Initialise RoBERTa en arri√®re-plan"""
        if not ROBERTA_AVAILABLE:
            print("‚ö†Ô∏è RoBERTa non disponible - mode fallback activ√©")
            return
            
        def load_roberta():
            try:
                print("ü§ñ Chargement de RoBERTa...")
                self.roberta_pipeline = pipeline(
                    "sentiment-analysis",
                    model="cardiffnlp/twitter-roberta-base-sentiment-latest",
                    truncation=True,
                    max_length=512,
                    device=-1
                )
                print("‚úÖ RoBERTa charg√© avec succ√®s !")
            except Exception as e:
                print(f"‚ùå Erreur chargement RoBERTa: {e}")
                self.roberta_pipeline = None
        
        load_roberta()
    
    def _apply_geopolitical_context(self, text: str, base_score: float) -> float:
        """
        üéØ Ajuste le score en fonction du contexte g√©opolitique
        """
        text_lower = text.lower()
        adjustment = 0.0
        matches = 0
        
        for term, modifier in self.geopolitical_modifiers.items():
            if term in text_lower:
                adjustment += modifier
                matches += 1
        
        # Moyenne des ajustements trouv√©s
        if matches > 0:
            adjustment = adjustment / matches
            # M√©lange avec le score de base (70% base, 30% contexte)
            adjusted_score = (base_score * 0.7) + (adjustment * 0.3)
            logger.debug(f"üéØ Ajustement g√©o: {base_score:.3f} ‚Üí {adjusted_score:.3f} ({matches} termes)")
            return adjusted_score
        
        return base_score
    
    def _smooth_score(self, score: float) -> float:
        """
        üìä Lisse le score pour √©viter les cat√©gorisations extr√™mes
        Applique une fonction sigmo√Øde douce
        """
        # Sigmo√Øde qui compresse les valeurs extr√™mes
        smoothed = np.tanh(score * 0.8)
        return float(smoothed)
    
    def _categorize_sentiment(self, score: float, confidence: float) -> str:
        """
        üè∑Ô∏è Cat√©gorise le sentiment avec prise en compte de la confiance
        """
        # Si confiance faible, pr√©f√©rer le neutre
        if confidence < 0.4:
            if score >= 0:
                return 'neutral_positive'
            else:
                return 'neutral_negative'
        
        # Cat√©gorisation normale
        if score >= self.thresholds['positive']:
            return 'positive'
        elif score >= self.thresholds['neutral_positive']:
            return 'neutral_positive'
        elif score >= self.thresholds['neutral_negative']:
            return 'neutral_negative'
        else:
            return 'negative'
    
    def analyze_sentiment_with_score(self, text: str) -> Dict[str, Any]:
        """
        ‚≠ê Analyse principale avec am√©liorations
        """
        if not text or len(text.strip()) < 10:
            return {
                'score': 0.0,
                'type': 'neutral_positive',
                'confidence': 0.0,
                'model': 'none'
            }
        
        # PRIORIT√â 1 : RoBERTa
        if self.roberta_pipeline:
            try:
                text_truncated = text[:500]
                result = self.roberta_pipeline(text_truncated)[0]
                
                label = result['label'].lower()
                raw_confidence = result['score']
                
                # Conversion Cardiff ‚Üí Score brut [-1, 1]
                if 'positive' in label:
                    raw_score = raw_confidence
                elif 'negative' in label:
                    raw_score = -raw_confidence
                else:
                    raw_score = 0.0
                
                # üéØ APPLICATION DU CONTEXTE G√âOPOLITIQUE
                geo_adjusted_score = self._apply_geopolitical_context(text, raw_score)
                
                # üìä LISSAGE
                smoothed_score = self._smooth_score(geo_adjusted_score)
                
                # üè∑Ô∏è CAT√âGORISATION INTELLIGENTE
                sentiment_type = self._categorize_sentiment(smoothed_score, raw_confidence)
                
                return {
                    'score': smoothed_score,
                    'type': sentiment_type,
                    'confidence': raw_confidence,
                    'model': 'roberta_enhanced',
                    'raw_score': raw_score,  # Pour debug
                    'geo_adjusted': geo_adjusted_score  # Pour debug
                }
                
            except Exception as e:
                logger.error(f"Erreur RoBERTa: {e}")
        
        # FALLBACK : M√©thode traditionnelle am√©lior√©e
        return self._analyze_traditional_enhanced(text)
    
    def _analyze_traditional_enhanced(self, text: str) -> Dict[str, Any]:
        """
        üìö Analyse traditionnelle avec am√©liorations
        """
        try:
            scores = []
            
            # TextBlob
            if TEXTBLOB_AVAILABLE:
                blob = TextBlob(text)
                scores.append(blob.sentiment.polarity)
            
            # VADER
            if self.sia:
                vader_scores = self.sia.polarity_scores(text)
                scores.append(vader_scores['compound'])
            
            # Moyenne des scores disponibles
            if scores:
                raw_score = np.mean(scores)
            else:
                raw_score = 0.0
            
            # üéØ Contexte g√©opolitique
            geo_adjusted = self._apply_geopolitical_context(text, raw_score)
            
            # üìä Lissage
            smoothed = self._smooth_score(geo_adjusted)
            
            # Confiance bas√©e sur l'accord entre mod√®les
            if len(scores) > 1:
                confidence = 1.0 - (np.std(scores) / 2.0)  # Plus d'accord = plus de confiance
            else:
                confidence = 0.5
            
            # üè∑Ô∏è Cat√©gorisation
            sentiment_type = self._categorize_sentiment(smoothed, confidence)
            
            return {
                'score': smoothed,
                'type': sentiment_type,
                'confidence': confidence,
                'model': 'traditional_enhanced',
                'raw_score': raw_score,
                'geo_adjusted': geo_adjusted
            }
            
        except Exception as e:
            logger.error(f"Erreur analyse traditionnelle: {e}")
            return {
                'score': 0.0,
                'type': 'neutral_positive',
                'confidence': 0.0,
                'model': 'error'
            }
    
    def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """M√©thode de compatibilit√©"""
        return self.analyze_sentiment_with_score(text)
    
    def analyze_article(self, title: str, content: str) -> Dict[str, Any]:
        """
        üì∞ Analyse d'article avec pond√©ration titre/contenu
        """
        # Le titre a plus d'importance (60/40)
        title_analysis = self.analyze_sentiment_with_score(title)
        content_analysis = self.analyze_sentiment_with_score(content[:1000])
        
        # Score combin√©
        combined_score = (title_analysis['score'] * 0.6) + (content_analysis['score'] * 0.4)
        combined_confidence = (title_analysis['confidence'] * 0.6) + (content_analysis['confidence'] * 0.4)
        
        # Recat√©gorisation
        sentiment_type = self._categorize_sentiment(combined_score, combined_confidence)
        
        return {
            'score': combined_score,
            'type': sentiment_type,
            'confidence': combined_confidence,
            'model': title_analysis['model'],
            'title_score': title_analysis['score'],
            'content_score': content_analysis['score']
        }
    
    def get_sentiment_explanation(self, result: Dict[str, Any]) -> str:
        """
        üí¨ G√©n√®re une explication textuelle du sentiment
        """
        score = result['score']
        sentiment = result['type']
        confidence = result['confidence']
        
        explanations = {
            'positive': f"Sentiment positif (score: {score:.2f}, confiance: {confidence:.0%})",
            'neutral_positive': f"L√©g√®rement positif (score: {score:.2f}, confiance: {confidence:.0%})",
            'neutral_negative': f"L√©g√®rement n√©gatif (score: {score:.2f}, confiance: {confidence:.0%})",
            'negative': f"Sentiment n√©gatif (score: {score:.2f}, confiance: {confidence:.0%})"
        }
        
        return explanations.get(sentiment, "Sentiment ind√©termin√©")